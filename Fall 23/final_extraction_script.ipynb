{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f8cd02-6130-4f62-a2bf-de4a35100ff8",
   "metadata": {
    "id": "62f8cd02-6130-4f62-a2bf-de4a35100ff8"
   },
   "outputs": [],
   "source": [
    "# needed packages\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import sys\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a910a9c2-4344-4a0f-acc7-d9c7588e8711",
   "metadata": {
    "id": "a910a9c2-4344-4a0f-acc7-d9c7588e8711"
   },
   "outputs": [],
   "source": [
    "def flags_decomposer(flags):\n",
    "    \"\"\"Make font flags human readable.\"\"\"\n",
    "    l = []\n",
    "    if flags & 2 ** 0:\n",
    "        l.append(\"superscript\")\n",
    "    if flags & 2 ** 1:\n",
    "        l.append(\"italic\")\n",
    "    if flags & 2 ** 2:\n",
    "        l.append(\"serifed\")\n",
    "    else:\n",
    "        l.append(\"sans\")\n",
    "    if flags & 2 ** 3:\n",
    "        l.append(\"monospaced\")\n",
    "    else:\n",
    "        l.append(\"proportional\")\n",
    "    if flags & 2 ** 4:\n",
    "        l.append(\"bold\")\n",
    "    return \", \".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b64860-83a2-4bd7-9e5b-2ec2b923f6a7",
   "metadata": {
    "id": "37b64860-83a2-4bd7-9e5b-2ec2b923f6a7"
   },
   "outputs": [],
   "source": [
    "def get_narrative(pdf):\n",
    "    doc = fitz.open(pdf)\n",
    "\n",
    "    style_counts = []\n",
    "\n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "\n",
    "        paths = page.get_drawings()  # get drawings on the page\n",
    "\n",
    "        drawn_lines = []\n",
    "        for p in paths:\n",
    "            # print(p)\n",
    "            for item in p[\"items\"]:\n",
    "                # print(item[0])\n",
    "                if item[0] == \"l\":  # an actual line\n",
    "                    # print(item[1], item[2])\n",
    "                    p1, p2 = item[1], item[2]\n",
    "                    if p1.y == p2.y:\n",
    "                        drawn_lines.append((p1, p2))\n",
    "                elif item[0] == \"re\":  # a rectangle: check if height is small\n",
    "                    # print(item[0])\n",
    "                    # print(item[1])\n",
    "                    r = item[1]\n",
    "                    if r.width > r.height and r.height <= 2:\n",
    "                        drawn_lines.append((r.tl, r.tr))  # take top left / right points\n",
    "\n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                for s in l[\"spans\"]:  # iterate through the text spans\n",
    "\n",
    "                    font_properties = \"Font: '%s' (%s), size %g, color #%06x\" % (\n",
    "                        s[\"font\"],  # font name\n",
    "                        flags_decomposer(s[\"flags\"]),  # readable font flags\n",
    "                        s[\"size\"],  # font size\n",
    "                        s[\"color\"],  # font color\n",
    "                    )\n",
    "\n",
    "                    r = fitz.Rect(s['bbox'])\n",
    "                    for p1, p2 in drawn_lines:  # check distances for start / end points\n",
    "                        if abs(r.bl - p1) <= 4 and abs(r.br - p2) <= 4:\n",
    "                            font_properties = \" \".join([font_properties, 'underlined'])\n",
    "\n",
    "                    style_counts.append(font_properties)\n",
    "\n",
    "    styles = dict(Counter(style_counts))\n",
    "\n",
    "    style_list = sorted(styles.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    headers = {}\n",
    "    count = 0\n",
    "    p_size = int(style_list[0][0].split('size')[1].split()[0].strip(','))\n",
    "\n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                texts = \"\"\n",
    "                count+=1\n",
    "                for s in l['spans']:\n",
    "                    if s['size'] >= p_size:\n",
    "                        texts = \"\".join ([texts, s['text']])\n",
    "                text_list = texts.split()\n",
    "                if len(text_list) > 0 and len(text_list) < 7:\n",
    "                    headers.update({texts:count})\n",
    "\n",
    "    opinion_loc = headers['Opinion']\n",
    "\n",
    "    count = 0\n",
    "    p_size = int(style_list[0][0].split('size')[1].split()[0].strip(','))\n",
    "    new_headers = {}\n",
    "    header_properties = \"\"\n",
    "\n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                count+=1\n",
    "                if count==opinion_loc:\n",
    "                    for s in l['spans']:\n",
    "                        header_properties = \"Font: '%s' (%s), size %g, color #%06x\" % (\n",
    "                            s[\"font\"],  # font name\n",
    "                            flags_decomposer(s[\"flags\"]),  # readable font flags\n",
    "                            s[\"size\"],  # font size\n",
    "                            s[\"color\"],  # font color\n",
    "                        )\n",
    "\n",
    "    count = 0\n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                count+=1\n",
    "                for s in l['spans']:\n",
    "                    font_properties = \"Font: '%s' (%s), size %g, color #%06x\" % (\n",
    "                        s[\"font\"],  # font name\n",
    "                        flags_decomposer(s[\"flags\"]),  # readable font flags\n",
    "                        s[\"size\"],  # font size\n",
    "                        s[\"color\"],  # font color\n",
    "                    )\n",
    "                    if font_properties==header_properties:\n",
    "                        new_headers.update({s['text']:count})\n",
    "\n",
    "    p_size = int(style_list[0][0].split('size')[1].split()[0].strip(','))\n",
    "    p_color = style_list[0][0].split('color')[1].split()[0].strip(',')\n",
    "    p_font = style_list[0][0]\n",
    "\n",
    "    bad_fonts = []\n",
    "\n",
    "    for style in style_list:\n",
    "        font_str = style[0]\n",
    "        s_size = int(font_str.split('size')[1].split()[0].strip(','))\n",
    "        s_color = font_str.split('color')[1].split()[0].strip(',')\n",
    "\n",
    "        # if font matches paragraph font, it's a bad_font\n",
    "        if font_str==p_font:\n",
    "            bad_fonts+=[font_str]\n",
    "        # if font doesn't match paragraph text color, it's a bad_font\n",
    "        if s_color!=p_color:\n",
    "            bad_fonts+=[font_str]\n",
    "        # if font matches characteristics of vocab word font, it's a bad font\n",
    "        if ('bold' in font_str and 'underlined' in font_str) and ('italic' in font_str and p_size==s_size):\n",
    "            bad_fonts+=[font_str]\n",
    "        # if font size is smaller than paragraph text size, it's a bad_font\n",
    "        if s_size<p_size:\n",
    "            bad_fonts+=[font_str]\n",
    "\n",
    "    master = []\n",
    "    for style in style_list:\n",
    "        if style[0] not in bad_fonts:\n",
    "            master += [style[0]]\n",
    "\n",
    "    for page in doc:\n",
    "\n",
    "        paths = page.get_drawings()  # get drawings on the page\n",
    "\n",
    "        drawn_lines = []\n",
    "        for p in paths:\n",
    "            # print(p)\n",
    "            for item in p[\"items\"]:\n",
    "                # print(item[0])\n",
    "                if item[0] == \"l\":  # an actual line\n",
    "                    # print(item[1], item[2])\n",
    "                    p1, p2 = item[1], item[2]\n",
    "                    if p1.y == p2.y:\n",
    "                        drawn_lines.append((p1, p2))\n",
    "                elif item[0] == \"re\":  # a rectangle: check if height is small\n",
    "                    # print(item[0])\n",
    "                    # print(item[1])\n",
    "                    r = item[1]\n",
    "                    if r.width > r.height and r.height <= 2:\n",
    "                        drawn_lines.append((r.tl, r.tr))  # take top left / right points\n",
    "\n",
    "    count = 0\n",
    "    opinion_subheaders = {}\n",
    "    p_color = style_list[0][0].split('color')[1].split()[0].strip(',')\n",
    "\n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                texts = \"\"\n",
    "                count+=1\n",
    "                span_fonts = []\n",
    "                if count>=opinion_loc:\n",
    "                    for s in l['spans']:\n",
    "                        font_properties = \"Font: '%s' (%s), size %g, color #%06x\" % (\n",
    "                            s[\"font\"],  # font name\n",
    "                            flags_decomposer(s[\"flags\"]),  # readable font flags\n",
    "                            s[\"size\"],  # font size\n",
    "                            s[\"color\"],  # font color\n",
    "                        )\n",
    "\n",
    "                        r = fitz.Rect(s['bbox'])\n",
    "                        for p1, p2 in drawn_lines:  # check distances for start / end points\n",
    "                            if abs(r.bl - p1) <= 4 and abs(r.br - p2) <= 4:\n",
    "                                font_properties = \" \".join([font_properties, 'underlined'])\n",
    "\n",
    "                        span_fonts+=[font_properties]\n",
    "                        texts = \"\".join ([texts, s['text']])\n",
    "\n",
    "                text_list = texts.split()\n",
    "                if len(text_list) > 0 and len(text_list) < 7:\n",
    "                    if any(i in span_fonts for i in master):\n",
    "                        opinion_subheaders.update({texts:count})\n",
    "                    if texts.isupper()==True:\n",
    "                        opinion_subheaders.update({texts:count})\n",
    "\n",
    "    narrative = \"\"\n",
    "    conclusion_loc = 100000\n",
    "    count = 0\n",
    "    p_size = int(style_list[0][0].split('size')[1].split()[0].strip(','))\n",
    "\n",
    "    keys_as_list = list(opinion_subheaders)\n",
    "    for header_index in range(len(keys_as_list)):\n",
    "        header = keys_as_list[header_index]\n",
    "        if 'conclusion' in header.lower():\n",
    "            conclusion_loc = opinion_subheaders[header]\n",
    "\n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                texts = \"\"\n",
    "                count+=1\n",
    "                if count>=opinion_loc and count < conclusion_loc:\n",
    "                    for s in l['spans']:\n",
    "                        if s['size'] == p_size:\n",
    "                            texts = \"\".join ([texts, s['text']])\n",
    "\n",
    "                narrative = \" \".join([narrative, texts])\n",
    "\n",
    "\n",
    "    return narrative.strip()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8d4f1fd-7cc3-4591-94db-26c49fe1a1a9",
   "metadata": {
    "id": "e8d4f1fd-7cc3-4591-94db-26c49fe1a1a9"
   },
   "source": [
    "### don't use this, try Tatev's first. Use if Tatev's doesn't work\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "pdf_files = glob.glob(\"%s/*.pdf\" % mypath)\n",
    "\n",
    "# Initialize DataFrame\n",
    "df = pd.DataFrame({\"CaseName\":[], \"Narrative\":[]})\n",
    "\n",
    "for idx, file in enumerate(pdf_files):\n",
    "    narrative = get_narrative(file)\n",
    "    df.loc[len(df)] = {\"CaseName\":os.path.basename(file), \"Narrative\":narrative}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd3a59e-e19d-42f9-8966-33ae804a1f65",
   "metadata": {
    "id": "6bd3a59e-e19d-42f9-8966-33ae804a1f65"
   },
   "outputs": [],
   "source": [
    "#### CHANGE FOR URSELF, folder with pdf cases in it\n",
    "mypath = \"C:/Users/jacqu/Downloads/Court Case PDFs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9bb0880-5e6b-4480-8a8f-750075ffc5bf",
   "metadata": {
    "id": "e9bb0880-5e6b-4480-8a8f-750075ffc5bf"
   },
   "outputs": [],
   "source": [
    "### Generate a df with your current cases\n",
    "import os\n",
    "import glob\n",
    "\n",
    "pdf_files = glob.glob(\"%s/Court Case PDFs/*.pdf\" % mypath)\n",
    "\n",
    "# Initialize DataFrame with corresponding row #\n",
    "df = pd.DataFrame(index=range(len(pdf_files)), columns=[\"CaseName\", \"Narrative\"])\n",
    "\n",
    "for idx, file in enumerate(pdf_files):\n",
    "    # Extract the title after the word \"cases\" in the file path\n",
    "    if \"50cases\" in file:\n",
    "        title = file.split(\"50cases/\")[-1].split(\"/\")[0]\n",
    "    else:\n",
    "        # Assuming the title is the filename without the extension\n",
    "        title = os.path.splitext(os.path.basename(file))[0]\n",
    "\n",
    "    narrative = get_narrative(file)\n",
    "\n",
    "    # Replace the 'CaseName' and 'Narrative' in the DataFrame directly\n",
    "    df.at[idx, \"CaseName\"] = title\n",
    "    df.at[idx, \"Narrative\"] = narrative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd3d20-eedd-4285-83ea-5675b34e1bb4",
   "metadata": {
    "id": "1ffd3d20-eedd-4285-83ea-5675b34e1bb4"
   },
   "source": [
    "# SERENE\n",
    "\n",
    "use this code to add your cases to the csv with all the cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ce49f3-0080-4ea4-9827-c7a3de5ba634",
   "metadata": {
    "id": "79ce49f3-0080-4ea4-9827-c7a3de5ba634"
   },
   "outputs": [],
   "source": [
    "drive_csv = \"/tatev_jacqui_grace.csv\"\n",
    "df2 = pd.read_csv(drive_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa2b9e-a251-4382-ab8a-676a87c32420",
   "metadata": {
    "id": "39fa2b9e-a251-4382-ab8a-676a87c32420"
   },
   "outputs": [],
   "source": [
    "## download the combined csv on google drive and combine with your csv for a new combined df\n",
    "combined_df = pd.concat([df, df2]).drop_duplicates()\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c026fd6b-dbb6-48d5-b0d2-77e17ea3d351",
   "metadata": {
    "id": "c026fd6b-dbb6-48d5-b0d2-77e17ea3d351"
   },
   "outputs": [],
   "source": [
    "# this function takes the pdf, extracted narrative, folder where your pdfs are stored, and folder where you want to store txt files\n",
    "# it processes each pdf file in your input folder to extract the narrative, and it saves it as a .txt file in your output folder\n",
    "# make sure to change path to input and output folders at the bottom\n",
    "\n",
    "def save_narrative_to_txt(pdf_path, narrative, output_folder, input_folder):\n",
    "    base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    txt_path = os.path.join(output_folder, f\"{base_name}.txt\")\n",
    "\n",
    "    with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(narrative)\n",
    "\n",
    "def process_pdfs(input_folder, output_folder):\n",
    "    pdf_files = glob.glob(os.path.join(input_folder, \"*.pdf\"))\n",
    "    narratives = []\n",
    "\n",
    "    for pdf_path in pdf_files:\n",
    "        # doc = fitz.open(pdf_path)\n",
    "        #style_list = get_styles(doc)\n",
    "        # opinion_loc = get_opinion(doc, style_list)\n",
    "        # master = get_master(style_list)\n",
    "        # opinion_subheaders = get_subheaders(doc, style_list, opinion_loc, master)\n",
    "\n",
    "        # keys_as_list = list(opinion_subheaders)\n",
    "        # for header_index in range(len(keys_as_list)):\n",
    "            # header = keys_as_list[header_index]\n",
    "\n",
    "        narrative = get_narrative(pdf_path)\n",
    "        narratives.append(narrative)\n",
    "\n",
    "        # Save narrative to text file in the same folder, overwriting existing files\n",
    "        save_narrative_to_txt(pdf_path, narrative, output_folder, input_folder)\n",
    "\n",
    "# Example usage:\n",
    "# input_folder = \"/Users/tatevgomtsyan/MSDS/Capstone/First12\"\n",
    "# output_folder = \"/Users/tatevgomtsyan/MSDS/Capstone/NarrativeTexts\"\n",
    "# process_pdfs(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f19033-8d09-412b-8817-1b9e88935552",
   "metadata": {
    "id": "97f270c6-2680-4f03-aae0-ba145885e595"
   },
   "outputs": [],
   "source": [
    "input_folder = f\"{mypath}/Court Case PDFs\"\n",
    "#### CHANGE FOR URSELF\n",
    "output_folder = f\"{mypath}/Court Case TXTs\"\n",
    "process_pdfs(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06d889-1365-4cdd-b49f-9ad3d136f809",
   "metadata": {
    "id": "8e06d889-1365-4cdd-b49f-9ad3d136f809"
   },
   "source": [
    "### Making combined csv\n",
    "1. download all cases and put into folder (called Court Case PDFs)\n",
    "2. create df with cases, the if statement takes care of pdf repeats, under the assumption that if someone uploaded the same case, the file would be renamed to have ({number}) at the end\n",
    "\n",
    "ex. C.S. Wyndham Hotels vs. C.S. Wyndham Hotels(1)\n",
    "\n",
    "3. test to make sure df converted to csv ok"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5db1275b-8b4c-4590-932f-026f429aec5c",
   "metadata": {
    "id": "5db1275b-8b4c-4590-932f-026f429aec5c"
   },
   "source": [
    "## all cases as of Dec 13 2023 4AM\n",
    "all_case_path = \"C:/Users/jacqu/Downloads/Court Case PDFs/Court Case PDFs\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "21b055ed-e9d9-4f24-b5b3-0f7ad09d68ea",
   "metadata": {
    "id": "21b055ed-e9d9-4f24-b5b3-0f7ad09d68ea"
   },
   "source": [
    "import re\n",
    "pdf_files = glob.glob(\"%s/*.pdf\" % all_case_path)\n",
    "\n",
    "# Initialize DataFrame\n",
    "df = pd.DataFrame({\"CaseName\":[], \"Narrative\":[]})\n",
    "\n",
    "for idx, file in enumerate(pdf_files):\n",
    "    if re.search(r\"\\(\\d+\\)\\.pdf\",file):\n",
    "        df = df\n",
    "    else:\n",
    "        narrative = get_narrative(file)\n",
    "        df.loc[len(df)] = {\"CaseName\":os.path.basename(file), \"Narrative\":narrative}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ac8b967-5d9c-412d-8ed7-a7f346cd9fd5",
   "metadata": {
    "id": "1ac8b967-5d9c-412d-8ed7-a7f346cd9fd5"
   },
   "source": [
    "pd.read_csv(mypath + \"/tatev_jacqui.csv\").head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
